{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftplib import FTP\n",
    "from dna_puller.sliding_parser import SlidingParser\n",
    "import os, gzip, json, csv, subprocess\n",
    "from gnuplot_generator.gnuplot_generator import GnuplotGenerator\n",
    "\n",
    "csv_folders = 'csv'\n",
    "window_size = 1000\n",
    "postfix = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is csv file from NCBI that contains name of species, other several atributtes and path of species data at FTP server \n",
    "# I recommend to create own CSV list on https://www.ncbi.nlm.nih.gov/genome/browse/#!/overview/\n",
    "# I also using there Pandas library for more straightfoward navigation in CSV, but python's  csv reader works well too. \n",
    "df = pd.read_csv(\"species_NCBI.csv\")\n",
    "\n",
    "links = df[['GenBank FTP']].values\n",
    "names = df[['#Organism Name']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "paths = {}\n",
    "\n",
    "def files_callback(name):\n",
    "    files_array.append(name)\n",
    "\n",
    "for index in range(len(links)):\n",
    "    link = links[index][0]\n",
    "    parts = link.split('/', maxsplit=3)\n",
    "    \n",
    "    next_path = (parts[3].split('/')[-1] + '_assembly_structure/') + 'Primary_Assembly/assembled_chromosomes/FASTA/'\n",
    "    ftp = FTP(parts[2])\n",
    "    ftp.login()\n",
    "    ftp.cwd(parts[3] + '/' + next_path)\n",
    "    paths[names[index][0]] = parts[3] + '/' + next_path\n",
    "    files_array = []\n",
    "    ftp.retrlines('NLST', callback = files_callback)\n",
    "    files[names[index][0]] = files_array\n",
    "    ftp.close()\n",
    "    \n",
    "for name, path in paths.items():\n",
    "    server = 'ftp.ncbi.nlm.nih.gov'\n",
    "    ftp = FTP(server)\n",
    "    ftp.login()\n",
    "    ftp.cwd(path)\n",
    "    \n",
    "    if not os.path.exists(name):\n",
    "        os.mkdir(name)\n",
    "    \n",
    "    if not os.path.exists(name + '/' + 'dna_sm'):\n",
    "        os.mkdir(name + '/' + 'dna_sm')\n",
    "        \n",
    "    for filename in files[name]:\n",
    "        print('download file: ' + filename)\n",
    "        file_path = os.path.join(name, 'dna_sm', filename)\n",
    "        fasta_path = os.path.join(name, 'dna_sm', filename[0:-3])\n",
    "        with open(file_path, 'wb') as file:\n",
    "            ftp.retrbinary('RETR ' + filename, file.write, 102400)\n",
    "        handle = gzip.open(file_path)\n",
    "        with open(fasta_path, 'wb') as out:\n",
    "            for line in handle:\n",
    "                out.write(line)\n",
    "    ftp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(names)):\n",
    "    name = names[index]\n",
    "    path = name + \"/dna_sm\"\n",
    "    data = {'dna_sm': {}}\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    fasta_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file[-3:] == '.fa':\n",
    "            fasta_files.append(file)\n",
    "    \n",
    "    for file in fasta_files:\n",
    "        parser = SlidingParser(window_size)\n",
    "        data['dna_sm'].update(parser.parse_file(path + \"/\" + file))\n",
    "    \n",
    "     if not os.path.exists('jsons'):\n",
    "        os.mkdir('jsons')\n",
    "        \n",
    "    json_path = os.path.join('jsons' , name + '.json')\n",
    "    print('creating ' + json_path)\n",
    "    with open(json_path, 'w') as fp:\n",
    "         json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_counts = {}\n",
    "\n",
    "for file in json_files:\n",
    "    name = file[:-5]\n",
    "    data = {}\n",
    "    if not os.path.exists('csv/' + name):\n",
    "        os.mkdir('csv/' + name)\n",
    "    with open('jsons/' + file) as f:\n",
    "        data = json.load(f)\n",
    "    file_counts[file] = {'sm': [], 'all': []}\n",
    "    for lg, values in data.items():\n",
    "        if lg[:2] == 'LR' or lg[:2] == 'CM':\n",
    "            with open('csv/' + name + '/' + lg + '.csv', 'w', newline='') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile, delimiter=' ',\n",
    "                                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "                for index, value in values.items():\n",
    "                    gc_count = value['G'] + value['C'] + value['S'] + value['g'] + value['c'] + value['s']\n",
    "                    all_count = value['all'] - value['N'] - value['n']\n",
    "\n",
    "                    big_percent = 0 \n",
    "                    if value['all_big'] > 0:\n",
    "                        big_percent = value['all_big'] / float(value['all'])\n",
    "                        if big_percent < 1:\n",
    "                            file_counts[file]['sm'].append(big_percent)\n",
    "                        file_counts[file]['all'].append(big_percent)\n",
    "\n",
    "                    if all_count > 0:\n",
    "                        gc_val = gc_count/all_count\n",
    "\n",
    "                    csvwriter.writerow([index, gc_val, big_percent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    p = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE, \n",
    "                                              stderr=subprocess.PIPE)\n",
    "    result, err = p.communicate()\n",
    "    if p.returncode != 0:\n",
    "        raise IOError(err)\n",
    "    return int(result.strip().split()[0])\n",
    "\n",
    "species_folders = []\n",
    "\n",
    "for folder in folders:\n",
    "    if folder[0] != '.':\n",
    "        species_folders.append(folder)\n",
    "\n",
    "files = {}\n",
    "biggest_files = {}\n",
    "sorted_files = {}\n",
    "for folder in species_folders:\n",
    "    biggest_files[folder] = 0\n",
    "    sorted_files[folder] = {}\n",
    "    csv_files = []\n",
    "    for file in os.listdir(csv_folders + '/' + folder):\n",
    "        if file[-4:] == '.csv':\n",
    "            csv_files.append(file)\n",
    "            \n",
    "            len_f =  file_len(csv_folders + '/' + folder + '/' + file)\n",
    "            sorted_files[folder][file] = len_f\n",
    "            if biggest_files[folder] < len_f * 1000:\n",
    "                biggest_files[folder] = len_f * 1000\n",
    "    files[folder] = csv_files \n",
    "    sorted_files[folder] = sorted(sorted_files[folder], key = sorted_files[folder].get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(fname):\n",
    "    p = subprocess.Popen(['gnuplot', '-p', fname], stdout=subprocess.PIPE, \n",
    "                                                   stderr=subprocess.PIPE)\n",
    "    result, err = p.communicate()\n",
    "    if p.returncode != 0:\n",
    "        raise IOError(err)           \n",
    "        \n",
    "for folder in species_folders:\n",
    "    range_plot = '[0:' + str(biggest_files[folder]) + ']'\n",
    "    gen = GnuplotGenerator(folder, range_plot)\n",
    "    gen.add_palette(\"( 0 'green', 50 'orange', 100 'red')\")\n",
    "    gen.set_term('png', 'plots_' + postfix + '/' + folder + '_' + postfix + '.png', 10000, 0.1)\n",
    "    \n",
    "    if not os.path.exists('plots_' + postfix):\n",
    "        os.makedirs('plots_' + postfix)\n",
    "    \n",
    "    for file in sorted_files[folder]:\n",
    "        gen.add_plot(csv_folders + '/' + folder + '/' + file, '1:2:3', file[:-4])\n",
    "    \n",
    "    with open(csv_folders + '/' + folder + '/' + folder + '_' + postfix + '.gnu', 'w') as gnu_file:\n",
    "        lines = gen.prepare_definition()\n",
    "        for line in lines:\n",
    "            gnu_file.write(line + '\\n')\n",
    "    \n",
    "    create_plot(csv_folders + '/' + folder + '/' + folder + '_' + postfix + '.gnu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
